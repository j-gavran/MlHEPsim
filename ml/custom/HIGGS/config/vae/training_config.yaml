training_config:
  learning_rate: 3.e-4
  epochs: 100

  optimizer: Adam
  early_stop_patience: 15
  weight_decay: 1.e-7

  scheduler:
    scheduler_name: CosineAnnealingWarmRestarts
    interval: step
    reduce_lr_on_epoch: 0.99
    scheduler_params:
      T_0: 964
      T_mult: 1
      eta_min: 0
