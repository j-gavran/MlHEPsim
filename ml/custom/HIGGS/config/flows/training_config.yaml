training_config:
  learning_rate: 3.e-4
  epochs: 150

  compile: False

  optimizer: Adam
  early_stop_patience: 6
  weight_decay: 1.e-7

  scheduler:
    scheduler_name: CosineAnnealingWarmRestarts
    interval: step
    reduce_lr_on_epoch: 0.995
    scheduler_params:
      T_0: 2020
      T_mult: 1
      eta_min: 0
